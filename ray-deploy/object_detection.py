import os
import torch
import wandb
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from pydantic import BaseModel

import ray
from ray import serve
from ray.serve.handle import DeploymentHandle

from model_def import LinearRegressionModel  # üîπ –Ü–º–ø–æ—Ä—Ç –∫–ª–∞—Å—É —Ç–≤–æ—î—ó –º–æ–¥–µ–ª—ñ

# FastAPI –¥–æ–¥–∞—Ç–æ–∫
app = FastAPI()

# üîπ Pydantic-—Å—Ö–µ–º–∞ –¥–ª—è –≤–≤–æ–¥—É —Ñ—ñ—á–µ–π
class Features(BaseModel):
    features: list[float]


@serve.deployment(
    num_replicas=1,
    ray_actor_options={"num_cpus": 1}
)
@serve.ingress(app)
class APIIngress:
    def __init__(self, object_detection_handle) -> None:
        self.handle: DeploymentHandle = object_detection_handle.options(
            use_new_handle_api=True
        )

    @app.post("/predict")
    async def predict(self, features: Features):
        result = await self.handle.predict.remote(features.features)
        return JSONResponse(content=result)


@serve.deployment(
    autoscaling_config={"min_replicas": 1, "max_replicas": 2},
    ray_actor_options={"num_cpus": 1}
)
class ObjectDetection:
    def __init__(self):
        self.wandb_project = os.getenv("WANDB_PROJECT", "linear-regression-pytorch")
        self.wandb_entity = os.getenv("WANDB_ENTITY", "s-oksana-set-university")
        self.model_artifact_name = os.getenv(
            "WANDB_MODEL_ARTIFACT",
            "s-oksana-set-university/linear-regression-pytorch/linear_regression_model:v0"
        )

        print("ü§ñ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è wandb —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
        os.environ["WANDB_MODE"] = "online"

        run = wandb.init(
            project=self.wandb_project,
            entity=self.wandb_entity,
            job_type="inference",
            mode="online"
        )

        try:
            api_key = os.getenv("WANDB_API_KEY")
            if not api_key:
                raise ValueError("WANDB_API_KEY not found in environment variables")

            print(f"üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—É –º–æ–¥–µ–ª—ñ: {self.model_artifact_name}")
            artifact = run.use_artifact(self.model_artifact_name, type='model')
            model_path = artifact.download()

            model_file = None
            for file in os.listdir(model_path):
                if file.endswith('.pt') or file.endswith('.pth'):
                    model_file = os.path.join(model_path, file)
                    break

            if model_file is None:
                raise FileNotFoundError("No .pt or .pth model file found in the downloaded artifact")

            print(f"üìÅ –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª—ñ: {model_file}")
            self.model = LinearRegressionModel()
            state_dict = torch.load(model_file, map_location=torch.device("cpu"))
            self.model.load_state_dict(state_dict)
            self.model.eval()
            print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –∑ wandb!")

        except Exception as e:
            print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å: {e}")
        finally:
            wandb.finish()

    async def predict(self, features: list[float]):
        print(f"üîç –û—Ç—Ä–∏–º–∞–Ω—ñ —Ñ—ñ—á—ñ: {features}")
        input_tensor = torch.tensor([features], dtype=torch.float32)

        with torch.no_grad():
            output = self.model(input_tensor).numpy().tolist()

        return {"status": "ok", "prediction": output}


# –ó–∞–ø—É—Å–∫
entrypoint = APIIngress.bind(ObjectDetection.bind())
